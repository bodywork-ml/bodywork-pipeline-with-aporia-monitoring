{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Use this notebook to train a model that solves our regression task and uploads the train model artefact to AWS S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import aporia\n",
    "import boto3 as aws\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import floating ,ndarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "AWS_S3_PROJECT_BUCKET = \"bodywork-pipeline-with-aporia-monitoring\"\n",
    "DATASET_URL = (\n",
    "    \"http://bodywork-pipeline-with-aporia-monitoring\"\n",
    "    \".s3.eu-west-2.amazonaws.com/datasets/dataset_t0.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data = pd.read_csv(urlopen(DATASET_URL))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Split labels from features and process categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_integer_map = {\"c0\": 0, \"c1\": 1, \"c2\": 2}\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df[\"F_2\"] = df[\"F_2\"].apply(lambda e: category_to_integer_map[e])\n",
    "\n",
    "    return df\n",
    "\n",
    "X = dataset[[\"F_1\", \"F_2\"]]\n",
    "y = dataset[\"y\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=dataset[\"F_2\"].values,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model Metrics\n",
    "\n",
    "We will use the Mean Absoloute Error (MAE) for this regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true: ndarray, y_pred: ndarray) -> floating:\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f\"MAPE = {mape/100:.2%}\")\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "We will train a decision tree, so that we can capture the non-linearities in the dataset and we will only use the default parameters, as the relationships between the labels, when conditioned on the categorical feature, is linear and should be easy to capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "model.fit(preprocess(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(preprocess(X_test))\n",
    "compute_metrics(y_test, y_test_pred)\n",
    "\n",
    "_ = sns.lmplot(\n",
    "    y=\"y_test_pred\",\n",
    "    x=\"y_test\",\n",
    "    data=pd.DataFrame({\"y_test\": y_test, \"y_test_pred\": y_test_pred}),\n",
    "    line_kws={\"color\": \"red\", \"alpha\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist trained model locally \n",
    "joblib.dump(model, \"model.joblib\")\n",
    "\n",
    "# upload trained model to AWS S3\n",
    "s3_client = aws.client('s3')\n",
    "s3_client.upload_file(\n",
    "    \"model.joblib\",\n",
    "    AWS_S3_PROJECT_BUCKET,\n",
    "    \"models/model.joblib\"\n",
    ")\n",
    "\n",
    "# remove local files\n",
    "os.remove(\"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Datasets to Aporia\n",
    "\n",
    "To use for monitoring live prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aporia.init(token=\"<APORIA_TOKEN>\", environment=\"training\", verbose=True)\r\n",
    "\r\n",
    "apr_model = aporia.create_model_version(\r\n",
    "    model_id=\"<APORIA_MODEL_ID>\",\r\n",
    "    model_version=\"<APORIA_MODEL_VERSION>\",\r\n",
    "    model_type=\"regression\",\r\n",
    "    raw_inputs={\r\n",
    "      \"F_1\": \"numeric\",\r\n",
    "      \"F_2\": \"string\",\r\n",
    "    },\r\n",
    "    features={\r\n",
    "      \"F_1\": \"numeric\",\r\n",
    "      \"F_2\": \"numeric\",\r\n",
    "    },\r\n",
    "    predictions={\r\n",
    "      \"y\": \"numeric\"\r\n",
    "    },\r\n",
    ")\r\n",
    "\r\n",
    "apr_model.log_training_set(\r\n",
    "  raw_inputs=X_train,\r\n",
    "  features=preprocess(X_train),\r\n",
    "  labels=y_train.to_frame(),\r\n",
    ")\r\n",
    "\r\n",
    "apr_model.log_test_set(\r\n",
    "  raw_inputs=X_test,\r\n",
    "  features=preprocess(X_test),\r\n",
    "  labels=y_test.to_frame(),\r\n",
    "  predictions=pd.DataFrame(columns=[\"y\"], data=y_test_pred),\r\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}